datasets:
  PixAICaption: # name of the dataset builder

    data_type: images # [images|videos|features]

    vis_processor:
        train:
          name: "blip2_image_train"
          image_size: 364
        eval:
          name: "blip_image_eval"
          image_size: 364
    text_processor:
        train:
          name: "blip_caption"
          prompt: "a photo of "
        eval:
          name: "blip_caption"

    build_info:
        images:
          storage: '/home/ubuntu/caption/images/'
        annotations:
          train:
            url: 'placeholder'
            storage: train-records.json
          val:
            url: 'placeholder'
            storage: val-records.json
          test:
            url: 'placeholder'
            storage: val-records.json
