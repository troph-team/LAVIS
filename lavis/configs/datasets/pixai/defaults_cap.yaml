datasets:
  PixAICaption: # name of the dataset builder

    data_type: images # [images|videos|features]

    vis_processor:
        train:
          name: "blip2_image_train"
          image_size: 364
        eval:
          name: "blip_image_eval"
          image_size: 364
    text_processor:
        train:
          name: "blip_caption"
          prompt: "a photo of "
        eval:
          name: "blip_caption"

    build_info:
        images:
          storage: '/export/share/datasets/vision/coco/images/'
        annotations:
          train:
            url: 'placeholder'
            storage: 415317_2023-06-27_all.json
          val:
            url: 'placeholder'
            storage: 415317_2023-06-27_all.json
          test:
            url: 'placeholder'
            storage: 415317_2023-06-27_all.json
